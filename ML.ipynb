{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import numpy as np\n",
    "import random\n",
    "import heapq\n",
    "from statistics import mode\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataPoints(filename):\n",
    "    data = np.loadtxt(filename, delimiter=',', dtype=str)\n",
    "\n",
    "    listofpoints = []\n",
    "\n",
    "    for d in data:\n",
    "        listofpoints.append(tuple(d))\n",
    "\n",
    "    ans = []\n",
    "    for tupl in listofpoints:\n",
    "        temp = []\n",
    "        for x in tupl:\n",
    "            try:\n",
    "                temp.append(float(x))\n",
    "            except Exception:\n",
    "                temp.append(x)\n",
    "        ans.append(tuple(temp))\n",
    "\n",
    "    return ans\n",
    "\n",
    "def getDimensions(data):\n",
    "    return len(data[0])\n",
    "\n",
    "def getTrainingAndTestsPoints(data):\n",
    "\n",
    "    seventyPercent = int((70/100)*len(data))\n",
    "    random.shuffle(data)\n",
    "\n",
    "    trainingPoints = data[:seventyPercent]\n",
    "    testPoints = data[seventyPercent + 1:]\n",
    "\n",
    "    return trainingPoints, testPoints\n",
    "\n",
    "def getUniqueClasses(data):\n",
    "    classes = []\n",
    "    dimension = getDimensions(data)\n",
    "\n",
    "    for p in data:\n",
    "        if classes.count(p[dimension-1]) == 0:\n",
    "            classes.append(p[dimension-1])\n",
    "\n",
    "    return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    def __init__(self, value, left, right):\n",
    "        self.value = value\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "\n",
    "def printPreorder(node):\n",
    "\n",
    "    if node:\n",
    "        print(node.value)\n",
    "        printPreorder(node.left)\n",
    "        printPreorder(node.right)\n",
    "\n",
    "def kdtree(point_list, depth=0):\n",
    "    try:\n",
    "        k = len(point_list[0]) - 1\n",
    "    except IndexError as e:\n",
    "        return None\n",
    "\n",
    "    if len(point_list) == 1:\n",
    "        return Node(value=point_list[0],left=None,right=None)\n",
    "\n",
    "    axis = depth % k\n",
    "\n",
    "    point_list.sort(key=lambda x: x[axis])\n",
    "    \n",
    "    l = len(point_list)\n",
    "    if l%2 == 0:\n",
    "        median = int((l/2)-1)\n",
    "    else:\n",
    "        median = l // 2\n",
    "\n",
    "    return Node(\n",
    "        value=point_list[median][axis],\n",
    "        left=kdtree(point_list[:median+1], depth + 1),\n",
    "        right=kdtree(point_list[median + 1:], depth + 1)\n",
    "    )\n",
    "class Kdtree():\n",
    "\n",
    "    def buildKdtree(point_list):\n",
    "        return kdtree(point_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclideanDistance(a, b):\n",
    "    return np.linalg.norm(np.asarray(a)-np.asarray(b))\n",
    "\n",
    "def k_nearestAux(dimensions, k, point, current_node, priority_queue=[], depth=0):\n",
    "\n",
    "    axis = depth % (dimensions-1)\n",
    "    depth += 1\n",
    "\n",
    "    if current_node.left == None and current_node.right == None:\n",
    "        distance = euclideanDistance(point[:dimensions-1], current_node.value[:dimensions-1])\n",
    "        if len(priority_queue) < k:\n",
    "            heapq.heappush(priority_queue, (-distance,current_node.value))\n",
    "            priority_queue = sorted(priority_queue)\n",
    "\n",
    "        elif -distance < -priority_queue[0][0]:\n",
    "            heapq.heappushpop(priority_queue, (-distance, current_node.value))\n",
    "            priority_queue = sorted(priority_queue)\n",
    "\n",
    "        return priority_queue\n",
    "\n",
    "    else:\n",
    "\n",
    "        if point[axis] > current_node.value:\n",
    "            nearBranch = current_node.right\n",
    "            opositeBranch = current_node.left\n",
    "        else:\n",
    "            nearBranch = current_node.left\n",
    "            opositeBranch = current_node.right\n",
    "\n",
    "        priority_queue = k_nearestAux(dimensions, k, point, nearBranch, priority_queue, depth)\n",
    "\n",
    "        if len(priority_queue) < k or priority_queue[0][1][axis] <= abs(point[axis] - current_node.value):\n",
    "\n",
    "            priority_queue = k_nearestAux(dimensions, k, point, opositeBranch, priority_queue, depth)\n",
    "\n",
    "        return priority_queue\n",
    "\n",
    "class Xnn():\n",
    "\n",
    "    def __init__(self, priority_queue):\n",
    "        self.priority_queue = priority_queue\n",
    "        self.kdtree = None\n",
    "\n",
    "    def buildKdtree(self, point_list):\n",
    "        self.kdtree = Kdtree.buildKdtree(point_list)\n",
    "\n",
    "    def k_nearest(self, dimensions, k, point, current_node):\n",
    "        self.priority_queue = k_nearestAux(dimensions, k, point, current_node, self.priority_queue, depth=0)\n",
    "\n",
    "    def getClassificationFromPQ(self, dimensions):\n",
    "        temp = []\n",
    "        for p in self.priority_queue:\n",
    "            temp.append(p[1][dimensions-1])\n",
    "\n",
    "        return mode(temp)\n",
    "\n",
    "    def getStatisticsFromTestPoints(self, k, test_point_list, classifications):\n",
    "        \n",
    "        tp = fp = tn = fn = 0\n",
    "        dimensions = getDimensions(test_point_list)\n",
    "        i = 0\n",
    "        for point in test_point_list:\n",
    "            self.k_nearest(dimensions, k, point, self.kdtree)\n",
    "            classification = self.getClassificationFromPQ(dimensions)\n",
    "            if point[dimensions-1] == classifications[0]:\n",
    "                if classification == point[dimensions-1]:\n",
    "                    tp += 1\n",
    "                else:\n",
    "                    fn += 1\n",
    "            else:\n",
    "                if classification == point[dimensions-1]:\n",
    "                    tn += 1\n",
    "                else:\n",
    "                    fp += 1\n",
    "        try:            \n",
    "            precision = tp/(tp + fp) * 100\n",
    "            revocation = tp/(tp+fn) * 100\n",
    "            accuracy = (tp+tn)/(tp+tn+fp+fn) * 100\n",
    "        except ZeroDivisionError:\n",
    "            precision = revocation = 0\n",
    "            accuracy = (tp+tn)/(tp+tn+fp+fn) * 100\n",
    "\n",
    "        print(\"Precisão: \", round(precision, 2), \"%\")\n",
    "        print(\"Revocação: \", round(revocation, 2), \"%\")\n",
    "        print(\"Acurácia: \", round(accuracy, 2), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_bayes_model = GaussianNB()\n",
    "decision_tree_model = DecisionTreeClassifier(max_depth=7)\n",
    "svm_model = svm.SVC(kernel='rbf')\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "random_forest_model = RandomForestClassifier(n_estimators=5)\n",
    "gradient_tree_boosting = GradientBoostingClassifier(n_estimators=4)\n",
    "\n",
    "models = [naive_bayes_model, decision_tree_model, svm_model, knn_model, random_forest_model, gradient_tree_boosting]\n",
    "models_name = ['Naive Bayes', 'Decision Tree', 'SVM', 'KNN', 'Random Forest', 'Gradient Tree Boosting']\n",
    "\n",
    "def getSklearnStatisticsFromTestPoints(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    for i in range(len(models)):\n",
    "        model = models[i].fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        print(\"Modelo: \", models_name[i])\n",
    "        acuraccy = metrics.accuracy_score(y_test, y_pred, normalize=True) * 100\n",
    "        recall = metrics.recall_score(y_test, y_pred, average='macro', zero_division=1) * 100\n",
    "        precision = metrics.precision_score(y_test, y_pred, average='macro', zero_division=1) * 100\n",
    "        print(\"Acurácia: %.2f\" % acuraccy)  \n",
    "        print(\"Revocação: %.2f\" % recall)  \n",
    "        print(\"Precisão: %.2f\" % precision) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidades de vizinhos próximos calculados:  5\n",
      "Database: drug200\n",
      "Precisão:  12.28 %\n",
      "Revocação:  87.5 %\n",
      "Acurácia:  13.56 %\n",
      "Modelo:  Naive Bayes\n",
      "Acurácia: 83.33\n",
      "Revocação: 92.59\n",
      "Precisão: 75.64\n",
      "Modelo:  Decision Tree\n",
      "Acurácia: 100.00\n",
      "Revocação: 100.00\n",
      "Precisão: 100.00\n",
      "Modelo:  SVM\n",
      "Acurácia: 76.67\n",
      "Revocação: 40.00\n",
      "Precisão: 91.52\n",
      "Modelo:  KNN\n",
      "Acurácia: 60.00\n",
      "Revocação: 31.23\n",
      "Precisão: 51.97\n",
      "Modelo:  Random Forest\n",
      "Acurácia: 96.67\n",
      "Revocação: 95.00\n",
      "Precisão: 95.67\n",
      "Modelo:  Gradient Tree Boosting\n",
      "Acurácia: 98.33\n",
      "Revocação: 97.50\n",
      "Precisão: 99.29\n"
     ]
    }
   ],
   "source": [
    "# databases = ['appendicitis', 'haberman', 'pima', 'led7digit', 'monk-2', 'heart', 'wdbc', 'phoneme', 'iris', 'ecoli', 'banana']\n",
    "databases = [\"drug200\"]\n",
    "\n",
    "k = 5\n",
    "print(\"Quantidades de vizinhos próximos calculados: \", k)\n",
    "\n",
    "for database in databases:\n",
    "    \n",
    "    #run my implementation of Xnn\n",
    "    print('Database: ' + database)\n",
    "    point_list = getDataPoints('data/' + database + '.csv')\n",
    "    trainingPoints, testPoints = getTrainingAndTestsPoints(point_list)\n",
    "\n",
    "    xnn = Xnn(priority_queue=[])\n",
    "    xnn.buildKdtree(trainingPoints)\n",
    "    xnn.getStatisticsFromTestPoints(k, testPoints, getUniqueClasses(testPoints))\n",
    "\n",
    "    #run sklearn models\n",
    "    df = pd.read_csv('data/' + database + '.csv')\n",
    "    X = df.iloc[:, :-1].values\n",
    "    y = df.iloc[:, -1].values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "    getSklearnStatisticsFromTestPoints(X_train, X_test, y_train, y_test)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "df5fc71a61a3929754bad503f46a5cedddd1f438fc1a250376ae010474d53aaf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
